{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-17 21:58:37.759082: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-17 21:58:38.438510: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/parlange/anaconda3/envs/bnn/lib/python3.11/site-packages/numba/core/decorators.py:262: NumbaDeprecationWarning: numba.generated_jit is deprecated. Please see the documentation at: https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-generated-jit for more information and advice on a suitable replacement.\n",
      "  warnings.warn(msg, NumbaDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os, json, sys, shutil\n",
    "from ovejero import model_trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting a Model Using model_trainer\n",
    "\n",
    "__Author:__ Sebastian Wagner-Carena\n",
    "\n",
    "__Last Run:__ 08/04/2020\n",
    "\n",
    "__Goals:__ Learn how to use model_trainer to fit the types of models used by ovejero\n",
    "\n",
    "__Before running this notebook:__ Run the Generate_Config notebook to understand what goes into the configuration files for overjero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by loading up the test configuration file made by Generate_Config and inspecting it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'training_params': {'bnn_type': 'gmm', 'dropout_type': 'standard', 'batch_size': 10, 'n_epochs': 100, 'learning_rate': 0.0001, 'decay': 3e-06, 'kernel_regularizer': 1e-05, 'dropout_rate': 0.1, 'dropout_regularizer': 1e-06, 'root_path': '/home/parlange/ovejero/test/test_data/', 'tf_record_path': 'tf_record_test', 'final_params': ['external_shear_g1', 'external_shear_g2', 'lens_mass_center_x', 'lens_mass_center_y', 'lens_mass_e1', 'lens_mass_e2', 'lens_mass_gamma', 'lens_mass_theta_E_log'], 'flip_pairs': [], 'img_dim': 128, 'model_weights': '/home/parlange/ovejero/test/test_data/test_model.h5', 'tensorboard_log_dir': '/home/parlange/ovejero/test/test_data/test.log', 'random_seed': 1138, 'norm_images': True, 'shift_pixels': 2, 'shift_params': [['lens_mass_center_x'], ['lens_mass_center_y']], 'pixel_scale': 0.051, 'baobab_config_path': '/home/parlange/ovejero/test/test_data/test_baobab_cfg.py'}, 'validation_params': {'root_path': '/home/parlange/ovejero/test/test_data/', 'tf_record_path': 'tf_record_test_val'}, 'dataset_params': {'lens_params_path': 'metadata.csv', 'new_param_path': 'new_metadata.csv', 'normalization_constants_path': 'norms.csv', 'lens_params': ['external_shear_gamma_ext', 'external_shear_psi_ext', 'lens_mass_center_x', 'lens_mass_center_y', 'lens_mass_e1', 'lens_mass_e2', 'lens_mass_gamma', 'lens_mass_theta_E'], 'lens_params_log': ['lens_mass_theta_E'], 'gampsi': {'gampsi_parameter_prefixes': ['external_shear'], 'gampsi_params_rat': ['external_shear_gamma_ext'], 'gampsi_params_ang': ['external_shear_psi_ext']}}, 'inference_params': {'final_params_print_names': ['$\\\\gamma_1$', '$\\\\gamma_2$', '$x_\\\\mathrm{lens}$', '$y_\\\\mathrm{lens}$', '$e_1$', '$e_2$', '$\\\\gamma_\\\\mathrm{lens}$', '$\\\\log(\\\\theta_E)$']}, 'forward_mod_params': {'lens_model_list': ['PEMD', 'SHEAR_GAMMA_PSI'], 'source_model_list': ['SERSIC_ELLIPSE']}}\n"
     ]
    }
   ],
   "source": [
    "json_path = '/home/parlange/ovejero/test/test_data/' + 'test.json'\n",
    "with open(json_path,'r') as json_f:\n",
    "    cfg = json.load(json_f)\n",
    "print(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of good information there! This is a good config file to start with. Let's go ahead and change a few paths and use it for our toy model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old path:\n",
      "/home/parlange/ovejero/test/test_data/test_model.h5\n",
      "new path:\n",
      "/home/parlange/ovejero/test/test_data/test_model.h5\n"
     ]
    }
   ],
   "source": [
    "# Change the model weights to point to the demo directory! Same for log file.\n",
    "print('old path:')\n",
    "print(cfg['training_params']['model_weights'])\n",
    "\n",
    "cfg['training_params']['model_weights'] = '/home/parlange/ovejero/test/test_data/test_model.h5'\n",
    "cfg['training_params']['tensorboard_log_dir'] = '/home/parlange/ovejero/test/test_data/test_logs'\n",
    "cfg['training_params']['baobab_config_path'] = '/home/parlange/ovejero/test/test_data/test_baobab_cfg.py'\n",
    "cfg['training_params']['root_path'] = '/home/parlange/ovejero/test/test_data/'\n",
    "cfg['validation_params']['root_path'] = '/home/parlange/ovejero/test/test_data/'\n",
    "print('new path:')\n",
    "print(cfg['training_params']['model_weights'])\n",
    "\n",
    "# Don't want shifts for this easier version of the problem\n",
    "cfg['training_params']['shift_pixels'] = 0\n",
    "\n",
    "# Also let's start with the easy diagonal case\n",
    "cfg['training_params']['bnn_type'] = 'diag'\n",
    "\n",
    "# Now let's go ahead and save this as our new configuration file\n",
    "diag_json_path = '/home/parlange/ovejero/test/test_data/diag.json'\n",
    "with open(diag_json_path,'w') as json_f:\n",
    "    json.dump(cfg,json_f,indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All we have to do is call the main function of model_trainer with the path to our config file! You should see the loss go down as the model learns to overfit to the lenses in the very small training set. Because the random seed is set by the configuration file the final loss should be 1.9520"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for training data.\n",
      "TFRecord found at /home/parlange/ovejero/test/test_data/tf_record_test\n",
      "Checking for validation data.\n",
      "TFRecord found at /home/parlange/ovejero/test/test_data/tf_record_test_val\n",
      "Initializing the model\n",
      "Is model built: True\n",
      "Loaded weights /home/parlange/ovejero/test/test_data/test_model.h5\n",
      "Epoch 1/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 1518.6422 - diagonal_covariance_loss: 1518.5377 - mse_loss: 2.1684"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/parlange/anaconda3/envs/bnn/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 5s 3s/step - loss: 1518.6422 - diagonal_covariance_loss: 1518.5377 - mse_loss: 2.1684 - val_loss: -0.0071 - val_diagonal_covariance_loss: -0.1097 - val_mse_loss: 0.4650\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 2s 950ms/step - loss: 1.3550 - diagonal_covariance_loss: 1.2531 - mse_loss: 0.6565 - val_loss: 3.5324 - val_diagonal_covariance_loss: 3.4330 - val_mse_loss: 0.9060\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 2s 905ms/step - loss: 3.4757 - diagonal_covariance_loss: 3.3772 - mse_loss: 0.8834 - val_loss: 3.6200 - val_diagonal_covariance_loss: 3.5244 - val_mse_loss: 0.9233\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 2s 985ms/step - loss: 3.2677 - diagonal_covariance_loss: 3.1731 - mse_loss: 0.8424 - val_loss: 3.5109 - val_diagonal_covariance_loss: 3.4193 - val_mse_loss: 0.9152\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 2s 905ms/step - loss: 3.8555 - diagonal_covariance_loss: 3.7650 - mse_loss: 1.0086 - val_loss: 3.3526 - val_diagonal_covariance_loss: 3.2653 - val_mse_loss: 0.9018\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 2s 994ms/step - loss: 3.1371 - diagonal_covariance_loss: 3.0508 - mse_loss: 0.8451 - val_loss: 3.0066 - val_diagonal_covariance_loss: 2.9236 - val_mse_loss: 0.8715\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 2s 986ms/step - loss: 3.3676 - diagonal_covariance_loss: 3.2857 - mse_loss: 0.9056 - val_loss: 2.6242 - val_diagonal_covariance_loss: 2.5455 - val_mse_loss: 0.8102\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 2s 967ms/step - loss: 2.6434 - diagonal_covariance_loss: 2.5658 - mse_loss: 0.7642 - val_loss: 2.3965 - val_diagonal_covariance_loss: 2.3222 - val_mse_loss: 0.7930\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 2s 927ms/step - loss: 2.3284 - diagonal_covariance_loss: 2.2551 - mse_loss: 0.7848 - val_loss: 2.1197 - val_diagonal_covariance_loss: 2.0496 - val_mse_loss: 0.7736\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 2s 904ms/step - loss: 2.3234 - diagonal_covariance_loss: 2.2544 - mse_loss: 0.8898 - val_loss: 1.7081 - val_diagonal_covariance_loss: 1.6422 - val_mse_loss: 0.6962\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 2s 958ms/step - loss: 1.3558 - diagonal_covariance_loss: 1.2909 - mse_loss: 0.6935 - val_loss: 1.4222 - val_diagonal_covariance_loss: 1.3603 - val_mse_loss: 0.6220\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 2s 974ms/step - loss: 1.8932 - diagonal_covariance_loss: 1.8323 - mse_loss: 0.7025 - val_loss: 0.9458 - val_diagonal_covariance_loss: 0.8878 - val_mse_loss: 0.5906\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 2s 941ms/step - loss: 0.8063 - diagonal_covariance_loss: 0.7492 - mse_loss: 0.5415 - val_loss: 0.8755 - val_diagonal_covariance_loss: 0.8211 - val_mse_loss: 0.5573\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 2s 915ms/step - loss: -0.2456 - diagonal_covariance_loss: -0.2990 - mse_loss: 0.4119 - val_loss: 0.9329 - val_diagonal_covariance_loss: 0.8821 - val_mse_loss: 0.5950\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 2s 925ms/step - loss: 2.0450 - diagonal_covariance_loss: 1.9950 - mse_loss: 0.7945 - val_loss: 1.4951 - val_diagonal_covariance_loss: 1.4475 - val_mse_loss: 0.6788\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 2s 911ms/step - loss: 0.9604 - diagonal_covariance_loss: 0.9136 - mse_loss: 0.5509 - val_loss: 0.9815 - val_diagonal_covariance_loss: 0.9371 - val_mse_loss: 0.6442\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 2s 972ms/step - loss: 0.7487 - diagonal_covariance_loss: 0.7050 - mse_loss: 0.5785 - val_loss: 0.6496 - val_diagonal_covariance_loss: 0.6081 - val_mse_loss: 0.5483\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 2s 994ms/step - loss: -0.0467 - diagonal_covariance_loss: -0.0876 - mse_loss: 0.5247 - val_loss: 0.0908 - val_diagonal_covariance_loss: 0.0519 - val_mse_loss: 0.5415\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 2s 983ms/step - loss: -0.9032 - diagonal_covariance_loss: -0.9415 - mse_loss: 0.4877 - val_loss: 0.2963 - val_diagonal_covariance_loss: 0.2598 - val_mse_loss: 0.5278\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 4s 3s/step - loss: -0.0899 - diagonal_covariance_loss: -0.1259 - mse_loss: 0.4979 - val_loss: -0.1615 - val_diagonal_covariance_loss: -0.1958 - val_mse_loss: 0.5361\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 2s 927ms/step - loss: 1.0775 - diagonal_covariance_loss: 1.0438 - mse_loss: 0.6174 - val_loss: 0.4802 - val_diagonal_covariance_loss: 0.4480 - val_mse_loss: 0.5484\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 2s 893ms/step - loss: 0.9820 - diagonal_covariance_loss: 0.9502 - mse_loss: 0.6190 - val_loss: 0.9238 - val_diagonal_covariance_loss: 0.8934 - val_mse_loss: 0.6284\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 2s 909ms/step - loss: 0.9555 - diagonal_covariance_loss: 0.9256 - mse_loss: 0.6476 - val_loss: 1.3205 - val_diagonal_covariance_loss: 1.2918 - val_mse_loss: 0.6821\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 2s 902ms/step - loss: 1.0517 - diagonal_covariance_loss: 1.0233 - mse_loss: 0.6068 - val_loss: 0.6849 - val_diagonal_covariance_loss: 0.6576 - val_mse_loss: 0.6188\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 2s 903ms/step - loss: -0.1684 - diagonal_covariance_loss: -0.1953 - mse_loss: 0.4968 - val_loss: 0.4366 - val_diagonal_covariance_loss: 0.4106 - val_mse_loss: 0.5385\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 2s 933ms/step - loss: -0.2274 - diagonal_covariance_loss: -0.2530 - mse_loss: 0.5397 - val_loss: -0.0854 - val_diagonal_covariance_loss: -0.1102 - val_mse_loss: 0.5306\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 2s 903ms/step - loss: 0.2622 - diagonal_covariance_loss: 0.2377 - mse_loss: 0.5719 - val_loss: 0.0114 - val_diagonal_covariance_loss: -0.0123 - val_mse_loss: 0.5157\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 2s 910ms/step - loss: -0.6119 - diagonal_covariance_loss: -0.6354 - mse_loss: 0.4290 - val_loss: 0.0410 - val_diagonal_covariance_loss: 0.0182 - val_mse_loss: 0.5187\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 2s 914ms/step - loss: -0.1644 - diagonal_covariance_loss: -0.1870 - mse_loss: 0.5744 - val_loss: 0.2034 - val_diagonal_covariance_loss: 0.1814 - val_mse_loss: 0.5167\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 2s 951ms/step - loss: 0.9639 - diagonal_covariance_loss: 0.9421 - mse_loss: 0.5894 - val_loss: 0.5755 - val_diagonal_covariance_loss: 0.5542 - val_mse_loss: 0.5455\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 2s 952ms/step - loss: -0.1612 - diagonal_covariance_loss: -0.1823 - mse_loss: 0.4258 - val_loss: 0.6066 - val_diagonal_covariance_loss: 0.5860 - val_mse_loss: 0.5526\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 2s 947ms/step - loss: 0.5298 - diagonal_covariance_loss: 0.5092 - mse_loss: 0.5787 - val_loss: 0.0623 - val_diagonal_covariance_loss: 0.0422 - val_mse_loss: 0.5175\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 5s 4s/step - loss: -0.4535 - diagonal_covariance_loss: -0.4736 - mse_loss: 0.5017 - val_loss: -0.4825 - val_diagonal_covariance_loss: -0.5022 - val_mse_loss: 0.4966\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 4s 3s/step - loss: -0.5693 - diagonal_covariance_loss: -0.5889 - mse_loss: 0.5148 - val_loss: -0.7451 - val_diagonal_covariance_loss: -0.7644 - val_mse_loss: 0.4723\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 2s 937ms/step - loss: 0.1954 - diagonal_covariance_loss: 0.1762 - mse_loss: 0.4459 - val_loss: -0.0491 - val_diagonal_covariance_loss: -0.0681 - val_mse_loss: 0.5296\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 2s 963ms/step - loss: 0.3962 - diagonal_covariance_loss: 0.3772 - mse_loss: 0.6545 - val_loss: 0.1616 - val_diagonal_covariance_loss: 0.1429 - val_mse_loss: 0.5650\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 2s 927ms/step - loss: 0.0715 - diagonal_covariance_loss: 0.0528 - mse_loss: 0.4806 - val_loss: 0.6448 - val_diagonal_covariance_loss: 0.6262 - val_mse_loss: 0.5998\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.4530 - diagonal_covariance_loss: 0.4345 - mse_loss: 0.5965 - val_loss: 0.1861 - val_diagonal_covariance_loss: 0.1677 - val_mse_loss: 0.5631\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: -0.0851 - diagonal_covariance_loss: -0.1034 - mse_loss: 0.5623 - val_loss: -0.1007 - val_diagonal_covariance_loss: -0.1190 - val_mse_loss: 0.5481\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 2s 975ms/step - loss: -1.0658 - diagonal_covariance_loss: -1.0840 - mse_loss: 0.3476 - val_loss: -0.4764 - val_diagonal_covariance_loss: -0.4946 - val_mse_loss: 0.5032\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 2s 939ms/step - loss: 0.4101 - diagonal_covariance_loss: 0.3919 - mse_loss: 0.6804 - val_loss: -0.7444 - val_diagonal_covariance_loss: -0.7625 - val_mse_loss: 0.4812\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 2s 973ms/step - loss: -0.1139 - diagonal_covariance_loss: -0.1320 - mse_loss: 0.4599 - val_loss: 0.2076 - val_diagonal_covariance_loss: 0.1896 - val_mse_loss: 0.5251\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 2s 963ms/step - loss: 0.4941 - diagonal_covariance_loss: 0.4760 - mse_loss: 0.6210 - val_loss: -0.4617 - val_diagonal_covariance_loss: -0.4797 - val_mse_loss: 0.4746\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 5s 4s/step - loss: -0.2507 - diagonal_covariance_loss: -0.2687 - mse_loss: 0.4689 - val_loss: -0.7540 - val_diagonal_covariance_loss: -0.7720 - val_mse_loss: 0.4815\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 5s 4s/step - loss: -1.1469 - diagonal_covariance_loss: -1.1649 - mse_loss: 0.4022 - val_loss: -0.9065 - val_diagonal_covariance_loss: -0.9244 - val_mse_loss: 0.4559\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 2s 899ms/step - loss: -0.9682 - diagonal_covariance_loss: -0.9861 - mse_loss: 0.4788 - val_loss: -0.5194 - val_diagonal_covariance_loss: -0.5373 - val_mse_loss: 0.4730\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 5s 4s/step - loss: -0.2210 - diagonal_covariance_loss: -0.2390 - mse_loss: 0.5176 - val_loss: -0.9131 - val_diagonal_covariance_loss: -0.9310 - val_mse_loss: 0.4421\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 6s 6s/step - loss: -0.6387 - diagonal_covariance_loss: -0.6567 - mse_loss: 0.4710 - val_loss: -1.6582 - val_diagonal_covariance_loss: -1.6762 - val_mse_loss: 0.4259\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 5s 4s/step - loss: -1.8691 - diagonal_covariance_loss: -1.8870 - mse_loss: 0.3906 - val_loss: -2.0076 - val_diagonal_covariance_loss: -2.0255 - val_mse_loss: 0.4068\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 2s 995ms/step - loss: 1.4193 - diagonal_covariance_loss: 1.4013 - mse_loss: 0.4097 - val_loss: -0.1125 - val_diagonal_covariance_loss: -0.1304 - val_mse_loss: 0.5054\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 2s 944ms/step - loss: 0.0225 - diagonal_covariance_loss: 0.0046 - mse_loss: 0.5542 - val_loss: 0.1137 - val_diagonal_covariance_loss: 0.0958 - val_mse_loss: 0.5355\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 2s 966ms/step - loss: 0.8526 - diagonal_covariance_loss: 0.8346 - mse_loss: 0.5802 - val_loss: 1.2127 - val_diagonal_covariance_loss: 1.1948 - val_mse_loss: 0.5964\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.2081 - diagonal_covariance_loss: 0.1902 - mse_loss: 0.5506 - val_loss: 0.5248 - val_diagonal_covariance_loss: 0.5068 - val_mse_loss: 0.5793\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 2s 986ms/step - loss: 0.5559 - diagonal_covariance_loss: 0.5379 - mse_loss: 0.6161 - val_loss: 0.4058 - val_diagonal_covariance_loss: 0.3877 - val_mse_loss: 0.5377\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 2s 959ms/step - loss: 0.4719 - diagonal_covariance_loss: 0.4538 - mse_loss: 0.5516 - val_loss: -0.2403 - val_diagonal_covariance_loss: -0.2584 - val_mse_loss: 0.5022\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 2s 926ms/step - loss: -0.4219 - diagonal_covariance_loss: -0.4400 - mse_loss: 0.4507 - val_loss: -0.3831 - val_diagonal_covariance_loss: -0.4013 - val_mse_loss: 0.4765\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: -0.6239 - diagonal_covariance_loss: -0.6421 - mse_loss: 0.4340 - val_loss: -0.9365 - val_diagonal_covariance_loss: -0.9548 - val_mse_loss: 0.4504\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 2s 966ms/step - loss: -1.8507 - diagonal_covariance_loss: -1.8689 - mse_loss: 0.4102 - val_loss: -1.1073 - val_diagonal_covariance_loss: -1.1256 - val_mse_loss: 0.4514\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 2s 940ms/step - loss: -0.0295 - diagonal_covariance_loss: -0.0477 - mse_loss: 0.5491 - val_loss: -1.2375 - val_diagonal_covariance_loss: -1.2558 - val_mse_loss: 0.4308\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: -1.6542 - diagonal_covariance_loss: -1.6725 - mse_loss: 0.3554 - val_loss: -1.2895 - val_diagonal_covariance_loss: -1.3078 - val_mse_loss: 0.4521\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.4087 - diagonal_covariance_loss: 0.3903 - mse_loss: 0.5934 - val_loss: -1.2320 - val_diagonal_covariance_loss: -1.2504 - val_mse_loss: 0.4430\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: -1.2919 - diagonal_covariance_loss: -1.3103 - mse_loss: 0.4483 - val_loss: -1.6041 - val_diagonal_covariance_loss: -1.6225 - val_mse_loss: 0.4357\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 5s 4s/step - loss: -1.8929 - diagonal_covariance_loss: -1.9113 - mse_loss: 0.4374 - val_loss: -2.0837 - val_diagonal_covariance_loss: -2.1022 - val_mse_loss: 0.3961\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 5s 4s/step - loss: -2.6158 - diagonal_covariance_loss: -2.6343 - mse_loss: 0.3225 - val_loss: -2.2324 - val_diagonal_covariance_loss: -2.2509 - val_mse_loss: 0.3897\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: -2.7347 - diagonal_covariance_loss: -2.7532 - mse_loss: 0.3025 - val_loss: -1.4194 - val_diagonal_covariance_loss: -1.4380 - val_mse_loss: 0.4353\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: -0.0187 - diagonal_covariance_loss: -0.0372 - mse_loss: 0.5360 - val_loss: -1.9796 - val_diagonal_covariance_loss: -1.9981 - val_mse_loss: 0.4088\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: -2.7482 - diagonal_covariance_loss: -2.7668 - mse_loss: 0.3801 - val_loss: -1.4957 - val_diagonal_covariance_loss: -1.5143 - val_mse_loss: 0.4319\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 5s 4s/step - loss: -1.7841 - diagonal_covariance_loss: -1.8027 - mse_loss: 0.3629 - val_loss: -2.4373 - val_diagonal_covariance_loss: -2.4559 - val_mse_loss: 0.3944\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.1353 - diagonal_covariance_loss: 0.1166 - mse_loss: 0.6197 - val_loss: -1.7912 - val_diagonal_covariance_loss: -1.8098 - val_mse_loss: 0.3983\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: -0.7120 - diagonal_covariance_loss: -0.7306 - mse_loss: 0.4566 - val_loss: -1.7204 - val_diagonal_covariance_loss: -1.7391 - val_mse_loss: 0.4243\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: -1.9033 - diagonal_covariance_loss: -1.9220 - mse_loss: 0.3742 - val_loss: -1.7539 - val_diagonal_covariance_loss: -1.7727 - val_mse_loss: 0.4105\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: -0.5670 - diagonal_covariance_loss: -0.5857 - mse_loss: 0.5230 - val_loss: -1.8651 - val_diagonal_covariance_loss: -1.8839 - val_mse_loss: 0.3930\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: -2.9638 - diagonal_covariance_loss: -2.9826 - mse_loss: 0.2981 - val_loss: -2.2965 - val_diagonal_covariance_loss: -2.3154 - val_mse_loss: 0.4039\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: -1.3648 - diagonal_covariance_loss: -1.3837 - mse_loss: 0.4077 - val_loss: -2.2285 - val_diagonal_covariance_loss: -2.2474 - val_mse_loss: 0.3857\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: -1.6007 - diagonal_covariance_loss: -1.6196 - mse_loss: 0.4608 - val_loss: -1.4239 - val_diagonal_covariance_loss: -1.4428 - val_mse_loss: 0.4371\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 6s 5s/step - loss: -2.3306 - diagonal_covariance_loss: -2.3495 - mse_loss: 0.3482 - val_loss: -2.5306 - val_diagonal_covariance_loss: -2.5496 - val_mse_loss: 0.3601\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: -2.3987 - diagonal_covariance_loss: -2.4177 - mse_loss: 0.4096 - val_loss: -2.2541 - val_diagonal_covariance_loss: -2.2732 - val_mse_loss: 0.3807\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: -1.5163 - diagonal_covariance_loss: -1.5353 - mse_loss: 0.4395 - val_loss: -2.2780 - val_diagonal_covariance_loss: -2.2970 - val_mse_loss: 0.3915\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: -2.7291 - diagonal_covariance_loss: -2.7482 - mse_loss: 0.3007 - val_loss: -2.2010 - val_diagonal_covariance_loss: -2.2201 - val_mse_loss: 0.3838\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 7s 6s/step - loss: -0.5236 - diagonal_covariance_loss: -0.5427 - mse_loss: 0.5506 - val_loss: -2.6401 - val_diagonal_covariance_loss: -2.6593 - val_mse_loss: 0.3679\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: -2.3194 - diagonal_covariance_loss: -2.3385 - mse_loss: 0.3466 - val_loss: -1.9446 - val_diagonal_covariance_loss: -1.9637 - val_mse_loss: 0.4070\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: -1.5668 - diagonal_covariance_loss: -1.5860 - mse_loss: 0.4008 - val_loss: -2.2316 - val_diagonal_covariance_loss: -2.2508 - val_mse_loss: 0.3900\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: -2.8803 - diagonal_covariance_loss: -2.8995 - mse_loss: 0.3803 - val_loss: -2.3623 - val_diagonal_covariance_loss: -2.3815 - val_mse_loss: 0.3815\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 6s 5s/step - loss: -1.4504 - diagonal_covariance_loss: -1.4696 - mse_loss: 0.4052 - val_loss: -2.8817 - val_diagonal_covariance_loss: -2.9010 - val_mse_loss: 0.3608\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: -2.8695 - diagonal_covariance_loss: -2.8888 - mse_loss: 0.3330 - val_loss: -2.0216 - val_diagonal_covariance_loss: -2.0409 - val_mse_loss: 0.3941\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 2s 907ms/step - loss: -2.6765 - diagonal_covariance_loss: -2.6959 - mse_loss: 0.3348 - val_loss: -2.7206 - val_diagonal_covariance_loss: -2.7399 - val_mse_loss: 0.3479\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: -1.1172 - diagonal_covariance_loss: -1.1366 - mse_loss: 0.4286 - val_loss: -2.3008 - val_diagonal_covariance_loss: -2.3202 - val_mse_loss: 0.3731\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 5s 4s/step - loss: -2.2314 - diagonal_covariance_loss: -2.2509 - mse_loss: 0.3795 - val_loss: -3.0331 - val_diagonal_covariance_loss: -3.0526 - val_mse_loss: 0.3551\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: -2.6365 - diagonal_covariance_loss: -2.6560 - mse_loss: 0.4015 - val_loss: -2.4510 - val_diagonal_covariance_loss: -2.4705 - val_mse_loss: 0.3641\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: -2.4544 - diagonal_covariance_loss: -2.4740 - mse_loss: 0.3925 - val_loss: -0.6601 - val_diagonal_covariance_loss: -0.6796 - val_mse_loss: 0.4402\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 2s 997ms/step - loss: -1.1863 - diagonal_covariance_loss: -1.2058 - mse_loss: 0.3947 - val_loss: -2.5407 - val_diagonal_covariance_loss: -2.5603 - val_mse_loss: 0.3637\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 2s 984ms/step - loss: -2.1742 - diagonal_covariance_loss: -2.1938 - mse_loss: 0.4524 - val_loss: -1.7656 - val_diagonal_covariance_loss: -1.7852 - val_mse_loss: 0.4264\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 2s 936ms/step - loss: -3.8589 - diagonal_covariance_loss: -3.8785 - mse_loss: 0.2413 - val_loss: -2.7238 - val_diagonal_covariance_loss: -2.7434 - val_mse_loss: 0.3872\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 2s 905ms/step - loss: -2.2041 - diagonal_covariance_loss: -2.2238 - mse_loss: 0.4316 - val_loss: -2.7737 - val_diagonal_covariance_loss: -2.7934 - val_mse_loss: 0.3894\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 2s 927ms/step - loss: 3.1489 - diagonal_covariance_loss: 3.1292 - mse_loss: 0.4500 - val_loss: -2.1967 - val_diagonal_covariance_loss: -2.2164 - val_mse_loss: 0.3804\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: -1.5253 - diagonal_covariance_loss: -1.5449 - mse_loss: 0.4335 - val_loss: 0.9173 - val_diagonal_covariance_loss: 0.8976 - val_mse_loss: 0.6542\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 2s 941ms/step - loss: 1.4275 - diagonal_covariance_loss: 1.4078 - mse_loss: 0.7014 - val_loss: 1.7790 - val_diagonal_covariance_loss: 1.7593 - val_mse_loss: 0.7227\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 2s 924ms/step - loss: 2.3198 - diagonal_covariance_loss: 2.3001 - mse_loss: 0.7422 - val_loss: 2.2472 - val_diagonal_covariance_loss: 2.2275 - val_mse_loss: 0.7787\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: 3.1065 - diagonal_covariance_loss: 3.0868 - mse_loss: 0.9431 - val_loss: 1.8715 - val_diagonal_covariance_loss: 1.8517 - val_mse_loss: 0.7423\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.9310 - diagonal_covariance_loss: 0.9112 - mse_loss: 0.5248 - val_loss: 2.1136 - val_diagonal_covariance_loss: 2.0939 - val_mse_loss: 0.7725\n"
     ]
    }
   ],
   "source": [
    "# This is equivalent to 'python -m model_trainer diag_json_path' in the terminal where diag_json_path is the path.\n",
    "sys.argv = ['model_trainer',diag_json_path]\n",
    "model_trainer.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end of each epoch we get the loss (which includes the concrete dropout regularization penalty) and the diagonal/full/gmm loss term (essentially the measure of how well our pdf is doing at capturing the data) on both the training and validation sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up the files that were created by this notebook.\n",
    "test_data_path = os.getcwd()[:-5]+'test/test_data/'\n",
    "\n",
    "os.remove(test_data_path+'new_metadata.csv')\n",
    "os.remove(test_data_path+'norms.csv')\n",
    "os.remove(test_data_path+'tf_record_test')\n",
    "os.remove(test_data_path+'tf_record_test_val')\n",
    "os.remove('test_model.h5')\n",
    "shutil.rmtree('test_logs')\n",
    "os.remove('diag.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to fit a different type of model, all we have to do is change the config specification for the bnn type or dropout rate."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
