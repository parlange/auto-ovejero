{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os, shutil\n",
    "from ovejero import model_trainer, hierarchical_inference\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib\n",
    "\n",
    "def NOTIMPLEMENTED():\n",
    "    raise NotImplementedError('Must specify config/save path')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical Inference on a Test Set\n",
    "\n",
    "__Author:__ Sebastian Wagner-Carena\n",
    "\n",
    "__Last Run:__ 08/15/2020\n",
    "\n",
    "__Goals:__ Learn how to run hierarchical inference on a test set using a trained BNN\n",
    "\n",
    "__Before running this notebook:__ Train a model and generate a test set on which you want to run hiearchical inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run hierarchical inference first we need to specify the path to the config files we'll use. There are three required configs for hierarchical inference:\n",
    "\n",
    "1. The ovejero bnn config used for training/validation/testing\n",
    "\n",
    "2. The ovejero distribution config that specifies the hyperparameters we'll run hierarchical inference over. For an example see the config in configs/baobab_configs/cent_narrow_cfg_prior.py.\n",
    "\n",
    "3. The baobab config used to geneate the training set.\n",
    "\n",
    "You can also optionally specify the baobab config used to generate the test set. This will be used to plot the true values of the hyperparameters you're trying to infer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is model built: True\n",
      "Loaded weights /home/parlange/ovejero/test/test_data/test_model.h5\n",
      "TFRecord found at /home/parlange/ovejero/test/test_data/tf_record_test_val\n",
      "TFRecord found at /home/parlange/ovejero/test/test_data/\n"
     ]
    }
   ],
   "source": [
    "# These are also optional, but these are the names of the hyperparameters and parameters of the lens sample.\n",
    "# They will only be used in plotting.\n",
    "hyperparam_plot_names = [r'$\\mu_{\\log(\\gamma_\\mathrm{ext})}$',r'$\\sigma_{\\log(\\gamma_\\mathrm{ext})}$',\n",
    "                         r'$\\mu_x$',r'$\\sigma_x$',r'$\\mu_y$',r'$\\sigma_y$',\n",
    "                         r'$\\mu_{e1}$',r'$\\sigma_{e1}$',\n",
    "                         r'$\\mu_{e2}$',r'$\\sigma_{e2}$',\n",
    "                         r'$\\mu_{\\log (\\gamma_\\mathrm{lens})}$',r'$\\sigma_{\\log (\\gamma_\\mathrm{lens})}$',\n",
    "                         r'$\\mu_{\\log (\\theta_E)}$',r'$\\sigma_{\\log (\\theta_E)}$']\n",
    "param_plot_names = [r'$\\gamma_\\mathrm{ext}$', r'$\\psi_\\mathrm{ext}$',r'$x_\\mathrm{lens}$',\n",
    "            r'$y_\\mathrm{lens}$',r'$e_1$',r'$e_2$',r'$\\gamma_\\mathrm{lens}$',r'$\\theta_E$']\n",
    "\n",
    "# The config path used to train the BNN\n",
    "bnn_config_path = '/home/parlange/ovejero/test/test_data/diag.json'\n",
    "bnn_cfg = model_trainer.load_config(bnn_config_path)\n",
    "\n",
    "def recursive_str_checker(cfg_dict):\n",
    "    for key in cfg_dict:\n",
    "        if isinstance(cfg_dict[key],str):\n",
    "            cfg_dict[key] = cfg_dict[key].replace('/home/swagnercarena/ovejero/', '/home/parlange/ovejero/')\n",
    "        if isinstance(cfg_dict[key],dict):\n",
    "            recursive_str_checker(cfg_dict[key])\n",
    "recursive_str_checker(bnn_cfg)\n",
    "\n",
    "# The baobab config used to generate the training set.\n",
    "interim_baobab_omega_path = '/home/parlange/ovejero/test/test_data/test_baobab_cfg.py'\n",
    "\n",
    "# The ovejero distribution config specifying the hyperparameters you want to fit.\n",
    "target_ovejero_omega_path = '/home/parlange/ovejero/configs/baobab_configs/test_ovejero_cfg_prior.py'\n",
    "\n",
    "# Optional, but you can also specify the baobab config used to generate the test set.\n",
    "#target_baobab_omega_path = '/home/parlange/ovejero/test/test_data/test_baobab_cfg_target.py'\n",
    "\n",
    "# The path to the test dataset\n",
    "test_dataset_path = '/home/parlange/ovejero/test/test_data/'\n",
    "\n",
    "# The path to which the tf record will be saved\n",
    "test_dataset_tf_record_path = '/home/parlange/ovejero/test/test_data/tfrecord/'\n",
    "\n",
    "# The number of walkers to use in the hierarchical inference. This should be AT LEAST double the number of\n",
    "# hyperparameters that are being inferred.\n",
    "n_walkers = 50\n",
    "\n",
    "# If you've already generated the samples you can set this to True. If you do, the weights won't be\n",
    "# loaded, avoiding memory errors.\n",
    "lite_class = False\n",
    "\n",
    "# The HierarchicalClass will do all the heavy lifting of preparing the model from the configuration file,\n",
    "# initializing the test dataset, and providing outputs correctly marginalized over the BNN uncertainties.\n",
    "# To initialize it we need to pass in our config files\n",
    "hier_infer = hierarchical_inference.HierarchicalClass(bnn_cfg,interim_baobab_omega_path,target_ovejero_omega_path,\n",
    "                                                      test_dataset_path,test_dataset_tf_record_path,\n",
    "                                                      target_baobab_omega_path=target_baobab_omega_path,\n",
    "                                                      lite_class=lite_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we've initialized our class, we need to generate bnn samples for the lenses in our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading samples from /home/parlange/ovejero/hierarchical_results_upload/cn_nn1_hr_samps/\n",
      "Loading samples from /home/parlange/ovejero/hierarchical_results_upload/cn_nn1_hr_samps/\n"
     ]
    }
   ],
   "source": [
    "# A path where the BNN samples will be saved\n",
    "save_path_samples = '/home/parlange/ovejero/hierarchical_results_upload/cn_nn1_hr_samps/'\n",
    "#save_path_samples = '/home/parlange/ovejero/test/test_data/bnnsamples/'\n",
    "\n",
    "# The number of BNN samples to draw per lens\n",
    "num_samples = 1000\n",
    "\n",
    "# This command will generate the samples on the test set\n",
    "hier_infer.gen_samples(num_samples, save_path_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run the hierarchical inference. We have to specify the number of walkers and the path to save the emcee samples to. We'll pick a specific path for the demo that we'll clear out later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No chains found at /home/parlange/ovejero/test/test_data/emcee/\n"
     ]
    },
    {
     "ename": "IsADirectoryError",
     "evalue": "[Errno 21] Unable to open file (unable to open file: name = '/home/parlange/ovejero/test/test_data/emcee/', errno = 21, error message = 'Is a directory', flags = 1, o_flags = 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m save_path_chains_hr \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/parlange/ovejero/test/test_data/emcee/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Initialize the sampler\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m hier_infer\u001b[38;5;241m.\u001b[39minitialize_sampler(n_walkers,save_path_chains_hr)\n",
      "File \u001b[0;32m~/ovejero/ovejero/hierarchical_inference.py:708\u001b[0m, in \u001b[0;36mHierarchicalClass.initialize_sampler\u001b[0;34m(self, n_walkers, save_path, pool)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend \u001b[38;5;241m=\u001b[39m emcee\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mHDFBackend(save_path)\n\u001b[1;32m    706\u001b[0m \u001b[38;5;66;03m# Very important I pass in prob_class.log_post_omega here to allow\u001b[39;00m\n\u001b[1;32m    707\u001b[0m \u001b[38;5;66;03m# pickling.\u001b[39;00m\n\u001b[0;32m--> 708\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampler \u001b[38;5;241m=\u001b[39m emcee\u001b[38;5;241m.\u001b[39mEnsembleSampler(n_walkers, ndim,\n\u001b[1;32m    709\u001b[0m \t\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprob_class\u001b[38;5;241m.\u001b[39mlog_post_omega, backend\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend,pool\u001b[38;5;241m=\u001b[39mpool)\n\u001b[1;32m    711\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampler_init \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/bnn/lib/python3.11/site-packages/emcee/ensemble.py:135\u001b[0m, in \u001b[0;36mEnsembleSampler.__init__\u001b[0;34m(self, nwalkers, ndim, log_prob_fn, pool, moves, args, kwargs, backend, vectorize, blobs_dtype, parameter_names, a, postargs, threads, live_dangerously, runtime_sortingfn)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39minitialized:\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_previous_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m    136\u001b[0m     state \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mget_state()\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;66;03m# Check the backend shape\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/bnn/lib/python3.11/site-packages/emcee/ensemble.py:242\u001b[0m, in \u001b[0;36mEnsembleSampler.reset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreset\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;124;03m    Reset the bookkeeping parameters\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \n\u001b[1;32m    241\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 242\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39mreset(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnwalkers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim)\n",
      "File \u001b[0;32m~/anaconda3/envs/bnn/lib/python3.11/site-packages/emcee/backends/hdf.py:113\u001b[0m, in \u001b[0;36mHDFBackend.reset\u001b[0;34m(self, nwalkers, ndim)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreset\u001b[39m(\u001b[38;5;28mself\u001b[39m, nwalkers, ndim):\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;124;03m\"\"\"Clear the state of the chain and empty the backend\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \n\u001b[1;32m    108\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    111\u001b[0m \n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;129;01min\u001b[39;00m f:\n\u001b[1;32m    115\u001b[0m             \u001b[38;5;28;01mdel\u001b[39;00m f[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname]\n",
      "File \u001b[0;32m~/anaconda3/envs/bnn/lib/python3.11/site-packages/emcee/backends/hdf.py:97\u001b[0m, in \u001b[0;36mHDFBackend.open\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread_only \u001b[38;5;129;01mand\u001b[39;00m mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     93\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe backend has been loaded in read-only \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode. Set `read_only = False` to make \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     95\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchanges.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     96\u001b[0m     )\n\u001b[0;32m---> 97\u001b[0m f \u001b[38;5;241m=\u001b[39m h5py\u001b[38;5;241m.\u001b[39mFile(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilename, mode)\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype_set \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;129;01min\u001b[39;00m f:\n\u001b[1;32m     99\u001b[0m     g \u001b[38;5;241m=\u001b[39m f[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname]\n",
      "File \u001b[0;32m~/anaconda3/envs/bnn/lib/python3.11/site-packages/h5py/_hl/files.py:567\u001b[0m, in \u001b[0;36mFile.__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    558\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[1;32m    559\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[1;32m    560\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[1;32m    561\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[1;32m    562\u001b[0m                      meta_block_size\u001b[38;5;241m=\u001b[39mmeta_block_size,\n\u001b[1;32m    563\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    564\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[1;32m    565\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[1;32m    566\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[0;32m--> 567\u001b[0m     fid \u001b[38;5;241m=\u001b[39m make_fid(name, mode, userblock_size, fapl, fcpl, swmr\u001b[38;5;241m=\u001b[39mswmr)\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[0;32m~/anaconda3/envs/bnn/lib/python3.11/site-packages/h5py/_hl/files.py:243\u001b[0m, in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;66;03m# Open in append mode (read/write).\u001b[39;00m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m# If that fails, create a new file only if it won't clobber an\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;66;03m# existing one (ACC_EXCL)\u001b[39;00m\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 243\u001b[0m         fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;66;03m# Not all drivers raise FileNotFoundError (commented those that do not)\u001b[39;00m\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m fapl\u001b[38;5;241m.\u001b[39mget_driver() \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m    246\u001b[0m         h5fd\u001b[38;5;241m.\u001b[39mSEC2,\n\u001b[1;32m    247\u001b[0m         h5fd\u001b[38;5;241m.\u001b[39mDIRECT \u001b[38;5;28;01mif\u001b[39;00m direct_vfd \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    255\u001b[0m         h5fd\u001b[38;5;241m.\u001b[39mROS3D \u001b[38;5;28;01mif\u001b[39;00m ros3 \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    256\u001b[0m     ) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5f.pyx:106\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Unable to open file (unable to open file: name = '/home/parlange/ovejero/test/test_data/emcee/', errno = 21, error message = 'Is a directory', flags = 1, o_flags = 2)"
     ]
    }
   ],
   "source": [
    "# Number of walkers\n",
    "n_walkers = 50\n",
    "\n",
    "# The path to save the emcee samples to\n",
    "save_path_chains_hr = '/home/parlange/ovejero/test/test_data/emcee/'\n",
    "\n",
    "# Initialize the sampler\n",
    "hier_infer.initialize_sampler(n_walkers,save_path_chains_hr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can run our hierarchical inference. For 100 steps this should take a few minutes (less when you have more cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Must generate samples before inference",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# We can run the sampler for 100 steps.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m num_emcee_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[0;32m----> 3\u001b[0m hier_infer\u001b[38;5;241m.\u001b[39mrun_sampler(num_emcee_samples,progress\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/ovejero/ovejero/hierarchical_inference.py:721\u001b[0m, in \u001b[0;36mHierarchicalClass.run_sampler\u001b[0;34m(self, n_samps, progress)\u001b[0m\n\u001b[1;32m    714\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;124;03mRun an emcee sampler to get a posterior on the hyperparameters.\u001b[39;00m\n\u001b[1;32m    716\u001b[0m \n\u001b[1;32m    717\u001b[0m \u001b[38;5;124;03mParameters:\u001b[39;00m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;124;03m\tn_samps (int): The number of samples to take\u001b[39;00m\n\u001b[1;32m    719\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    720\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprob_class\u001b[38;5;241m.\u001b[39msamples_init \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m--> 721\u001b[0m \t\u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMust generate samples before inference\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    722\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampler_init \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    723\u001b[0m \t\u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMust initialize sampler before running sampler\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Must generate samples before inference"
     ]
    }
   ],
   "source": [
    "# We can run the sampler for 100 steps.\n",
    "num_emcee_samples = 100\n",
    "hier_infer.run_sampler(num_emcee_samples,progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "100 steps isn't enough for convergence, but we can still inspect the chains. The HierarchicalInference class allows us to plot the chains and to do some basic autocorrelation analysis. Neither plot should make you feel like things have converged in 100 steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "burnin = 0\n",
    "hier_infer.plot_chains(burnin=burnin,hyperparam_plot_names=hyperparam_plot_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hier_infer.plot_auto_corr(hyperparam_plot_names=hyperparam_plot_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class also allows us to inspect the results of the hierarchical inference and generate some nice plots. For an example check the hierarchical inference notebook in the papers folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the weights we generated.\n",
    "os.remove('demo_hier_samples.h5')\n",
    "shutil.rmtree('fow_model_bnn_samps')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bnn",
   "language": "python",
   "name": "bnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
