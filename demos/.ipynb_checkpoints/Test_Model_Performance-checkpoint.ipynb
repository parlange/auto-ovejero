{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-14 01:23:12.349813: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-14 01:23:12.383844: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-14 01:23:12.384402: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-14 01:23:13.102763: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/parlange/anaconda3/envs/bnn/lib/python3.11/site-packages/numba/core/decorators.py:262: NumbaDeprecationWarning: numba.generated_jit is deprecated. Please see the documentation at: https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-generated-jit for more information and advice on a suitable replacement.\n",
      "  warnings.warn(msg, NumbaDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "from ovejero import model_trainer, data_tools, bnn_inference\n",
    "import corner\n",
    "import os\n",
    "\n",
    "def NOTIMPLEMENTED():\n",
    "    raise NotImplementedError('Must specify config/save path')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the Performance of a Model That Has Been Fit\n",
    "\n",
    "__Author:__ Sebastian Wagner-Carena\n",
    "\n",
    "__Last Run:__ 08/04/2020\n",
    "\n",
    "__Goals:__ Learn how to test the performance of a trained model on the validation set.\n",
    "\n",
    "__Before running this notebook:__ Run the Train_Toy_Model notebook to understand how to train a model. Then train a model with whatever configuration you want. You will have to add the path to the config file in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start, all we have to do is load up our model weights and run it on the validation set. Thankfully, that's pretty easy to do with the BNN inference class. If you don't have a GPU, generating samples for the full validation set can be time consuming (30-40 minutes for 1000 samples). However, by specifying a save path for the samples we only need to do this once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is model built: True\n",
      "No weights found. Saving new weights to ./test_data/test_model.h5\n",
      "Generating new TFRecord at ./test_data/tf_record_test_val\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './test_data/metadata.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m cfg \u001b[38;5;241m=\u001b[39m model_trainer\u001b[38;5;241m.\u001b[39mload_config(config_path)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# The InferenceClass will do all the heavy lifting of preparing the model from the configuration file,\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# initializing the validation dataset, and providing outputs correctly marginalized over the BNN uncertainties.\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m bnn_infer \u001b[38;5;241m=\u001b[39m bnn_inference\u001b[38;5;241m.\u001b[39mInferenceClass(cfg)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Now we just have to ask the InferenceClass to spin up some samples from our BNN. The more samples, the more\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# accurate our plots and metrics will be. The right value to use unfortunately requires a bit of trial and error.\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# 1000 is a good starting point though.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m num_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m\n",
      "File \u001b[0;32m~/ovejero/ovejero/bnn_inference.py:76\u001b[0m, in \u001b[0;36mInferenceClass.__init__\u001b[0;34m(self, cfg, lite_class, test_set_path)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtf_record_path_v):\n\u001b[1;32m     75\u001b[0m \t\u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGenerating new TFRecord at \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m%\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtf_record_path_v))\n\u001b[0;32m---> 76\u001b[0m \tmodel_trainer\u001b[38;5;241m.\u001b[39mprepare_tf_record(cfg,\n\u001b[1;32m     77\u001b[0m \t\tcfg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidation_params\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroot_path\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     78\u001b[0m \t\t\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtf_record_path_v,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_params,\n\u001b[1;32m     79\u001b[0m \t\ttrain_or_test\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     81\u001b[0m \t\u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTFRecord found at \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m%\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtf_record_path_v))\n",
      "File \u001b[0;32m~/ovejero/ovejero/model_trainer.py:132\u001b[0m, in \u001b[0;36mprepare_tf_record\u001b[0;34m(cfg, root_path, tf_record_path, final_params, train_or_test)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;66;03m# First write desired parameters in log space.\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lens_params_log \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 132\u001b[0m \tdata_tools\u001b[38;5;241m.\u001b[39mwrite_parameters_in_log_space(lens_params_log,\n\u001b[1;32m    133\u001b[0m \t\tlens_params_path,new_param_path)\n\u001b[1;32m    134\u001b[0m \t\u001b[38;5;66;03m# Add log version of parameter.\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \t\u001b[38;5;28;01mfor\u001b[39;00m lens_param_log \u001b[38;5;129;01min\u001b[39;00m lens_params_log:\n",
      "File \u001b[0;32m~/ovejero/ovejero/data_tools.py:93\u001b[0m, in \u001b[0;36mwrite_parameters_in_log_space\u001b[0;34m(lens_params, lens_params_path, new_lens_params_path)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;124;03mConvert lens parameters to log space (important for parameters that cannot\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;124;03mbe negative)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;124;03m\t'lens parameter name'_log\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;66;03m# Read the lens parameters from the csv file\u001b[39;00m\n\u001b[0;32m---> 93\u001b[0m lens_params_csv \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(lens_params_path, index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m lens_param \u001b[38;5;129;01min\u001b[39;00m lens_params:\n\u001b[1;32m     96\u001b[0m \tlens_params_csv[lens_param\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_log\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(lens_params_csv[lens_param])\n",
      "File \u001b[0;32m~/anaconda3/envs/bnn/lib/python3.11/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/anaconda3/envs/bnn/lib/python3.11/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/envs/bnn/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m~/anaconda3/envs/bnn/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1662\u001b[0m     f,\n\u001b[1;32m   1663\u001b[0m     mode,\n\u001b[1;32m   1664\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1665\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1666\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1667\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1668\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1669\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1670\u001b[0m )\n\u001b[1;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/envs/bnn/lib/python3.11/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    860\u001b[0m             handle,\n\u001b[1;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    862\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    863\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    865\u001b[0m         )\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './test_data/metadata.csv'"
     ]
    }
   ],
   "source": [
    "# First specify the config path\n",
    "config_path = '/home/parlange/ovejero/test/test_data/test.json'\n",
    "\n",
    "# Check that the config has what you need\n",
    "cfg = model_trainer.load_config(config_path)\n",
    "\n",
    "# The InferenceClass will do all the heavy lifting of preparing the model from the configuration file,\n",
    "# initializing the validation dataset, and providing outputs correctly marginalized over the BNN uncertainties.\n",
    "bnn_infer = bnn_inference.InferenceClass(cfg)\n",
    "\n",
    "# Now we just have to ask the InferenceClass to spin up some samples from our BNN. The more samples, the more\n",
    "# accurate our plots and metrics will be. The right value to use unfortunately requires a bit of trial and error.\n",
    "# 1000 is a good starting point though.\n",
    "num_samples = 1000\n",
    "sample_save_dir =  r'/home/parlange/ovejero/test/test_data/'\n",
    "bnn_infer.gen_samples(num_samples,sample_save_dir=sample_save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we set up our infastructure, the first thing we want to do is inspect the statistics of our network's performance over the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnn_infer.report_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also inspect a coverage plot of our parameters. If our model is performing well, we expect our data to roughly follow the 68-95-99.7 rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnn_infer.gen_coverage_plots()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another good check is to see the posterior of some example images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_index = 5\n",
    "bnn_infer.plot_posterior_contours(image_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important to understand where our uncertainty is coming from. We can inspect wether our uncertainty is dominated by aleatoric or epistemic sources. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnn_infer.comp_al_ep_unc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end what we want our network's posterior to be well calibrated. That means that the truth should be a representative draw from the distribution we're predicting. The exact sampling that goes into the calibration plot is complicated, but the x axis repesents how much of the data the model expects to fall within a certain region of our posterior, and the y axis represents how much data actually falls within that region. Ideally this would be a straight line (y=x), but in practice our model is likely to be overconfident, underconfident, or some combination of both. The lower right hand corner of our plot represents overconfidence, and the upper right hand corner represents underconfidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_map = [\"#377eb8\", \"#4daf4a\"]\n",
    "n_perc_points = 30\n",
    "fig = bnn_infer.plot_calibration(color_map=color_map,n_perc_points=n_perc_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Understanding the Calibration Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughout our paper we argue that the calibration plot is the best metric to asses the quality of the BNN posterior. Here, we include a few examples to give a better feel for the calibration plot. We focus on toy 2D models since those are easy to visualize and conceptualize. We can start with a biased 2D posterior prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we'll make a class to generate our comparison\n",
    "matplotlib.rcParams.update({'font.size': 13})\n",
    "def plot_toy_model_calibration(data_mean,data_cov,post_mean,post_cov,toy_batch_size,n_draws,\n",
    "                              fit_guass_data=False):\n",
    "    bnn_toy = bnn_inference.InferenceClass(cfg)\n",
    "    # We generate our toy data \n",
    "    data = np.random.multivariate_normal(data_mean,data_cov,(toy_batch_size))\n",
    "\n",
    "    # Now we generate our posterior means and covariances\n",
    "    post_samples = np.random.multivariate_normal(post_mean,post_cov,(n_draws,toy_batch_size))\n",
    "\n",
    "    # We change our bnn inference instance to have these values\n",
    "    bnn_toy.samples_init = True\n",
    "    bnn_toy.y_pred = np.mean(post_samples,axis=0)\n",
    "    bnn_toy.predict_samps = post_samples\n",
    "    bnn_toy.y_test = data\n",
    "    \n",
    "    # We can visualize the true data and the posterior, and compare that to the calibration plot.\n",
    "    color_map=[\"#377eb8\", \"#4daf4a\"]\n",
    "    fig = corner.corner(post_samples.reshape(-1,2),bins=20,labels=['x','y'],show_titles=False, plot_datapoints=False,\n",
    "                  label_kwargs=dict(fontsize=15),levels=[0.68,0.95],dpi=200, \n",
    "                  color=color_map[1],fill_contours=True,range=[[-6,6],[-6,6]])\n",
    "    fig.axes[2].plot(data[:,0],data[:,1],'.',c=color_map[0],alpha=0.1)\n",
    "    post_line = mlines.Line2D([], [], color=color_map[0], label='True Posterior')\n",
    "    data_line = mlines.Line2D([], [], color=color_map[1], label='Inferred Posterior')\n",
    "    plt.legend(handles=[post_line,data_line], bbox_to_anchor=(0.05, 1.0, 1., .0), loc=4,fontsize=12)\n",
    "    plt.show()\n",
    "    \n",
    "    cal_fig = bnn_toy.plot_calibration(n_perc_points=30,title='',\n",
    "                                       legend=['Perfect Calibration','Inferred Posterior Calibration'])\n",
    "    \n",
    "    return (fig,cal_fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We start with our offset posterior\n",
    "data_mean = np.zeros(2)\n",
    "data_cov = np.eye(2)\n",
    "toy_batch_size = 10000\n",
    "n_draws = 1000\n",
    "post_mean = np.ones(2)*2\n",
    "post_cov=np.eye(2)\n",
    "post_fig, cal_fig = plot_toy_model_calibration(data_mean,data_cov,post_mean,post_cov,toy_batch_size,n_draws)\n",
    "post_fig.savefig('../paper/figures/appendix/offset_corn.pdf')\n",
    "cal_fig.savefig('../paper/figures/appendix/offset_cal.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The posterior we're predicting is offset from the truth, so our model is consistently overconfident. We can repeat the exercise with a posterior that is correctly centered but has a much tighter contour. We still expect our model to be overconfident."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mean = np.zeros(2)\n",
    "data_cov = np.eye(2)\n",
    "toy_batch_size = 10000\n",
    "n_draws = 1000\n",
    "post_mean = np.zeros(2)\n",
    "post_cov=np.eye(2)*0.3\n",
    "_ = plot_toy_model_calibration(data_mean,data_cov,post_mean,post_cov,toy_batch_size,n_draws = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, our model is overconfident. We can similary see what happens when our model is underconfident by expanding our contours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mean = np.zeros(2)\n",
    "data_cov = np.eye(2)\n",
    "toy_batch_size = 10000\n",
    "n_draws = 1000\n",
    "post_mean = np.zeros(2)\n",
    "post_cov=np.eye(2)*3\n",
    "post_fig, cal_fig = plot_toy_model_calibration(data_mean,data_cov,post_mean,post_cov,toy_batch_size,n_draws)\n",
    "post_fig.savefig('../paper/figures/appendix/underconf_corn.pdf')\n",
    "cal_fig.savefig('../paper/figures/appendix/underconf_cal.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model posterior here is underconfident - almost 90% of the data falls within the 1 sigma countour. We can look at a more realistic example - a Gaussian posterior with no covariance trying to fit data with covariance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We start with our offset posterior\n",
    "data_mean = np.zeros(2)\n",
    "data_cov = np.array([[1,0.99],[0.99,1]])\n",
    "toy_batch_size = 10000\n",
    "n_draws = 1000\n",
    "post_mean = np.zeros(2)\n",
    "post_cov=np.diag(np.std(np.random.multivariate_normal(data_mean,data_cov,(toy_batch_size)),axis=0))\n",
    "_ = plot_toy_model_calibration(data_mean,data_cov,post_mean,post_cov,toy_batch_size,n_draws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This comes off mostly as overconfident by our network - it's not capturing the extreme covariance in the data, causing the networks contours to assign too little probabilistic weight to the tails."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another issue our network may have is that the posterior we pick is not sufficiently multimodal to capture the true distribution of the data (or the multimodality is poorly tuned). We can see what this looks like by fitting a full covariance matrix posterior to multimodal data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we'll make a class to generate our comparison\n",
    "def plot_toy_model_calibration_gm(data_means,data_covs,post_mean,post_cov,toy_batch_size,ps,n_draws,\n",
    "                              fit_guass_data=False):\n",
    "    bnn_toy = bnn_inference.InferenceClass(cfg)\n",
    "    # We generate our toy data \n",
    "    data = []\n",
    "    for dmi in range(len(data_means)):\n",
    "        data.append(np.random.multivariate_normal(data_means[dmi],data_covs[dmi],(int(toy_batch_size*ps[dmi]))))\n",
    "    data = np.concatenate(data,axis=0)\n",
    "    \n",
    "    if fit_guass_data == True:\n",
    "        post_mean = np.mean(data,axis=0)\n",
    "        post_cov=np.diag(np.std(data,axis=0))\n",
    "\n",
    "    # Now we generate our posterior means and covariances\n",
    "    post_samples = np.random.multivariate_normal(post_mean,post_cov,(n_draws,toy_batch_size))\n",
    "\n",
    "    # We change our bnn inference instance to have these values\n",
    "    bnn_toy.samples_init = True\n",
    "    bnn_toy.y_pred = np.mean(post_samples,axis=0)\n",
    "    bnn_toy.predict_samps = post_samples\n",
    "    bnn_toy.y_test = data\n",
    "    \n",
    "    # We can visualize the true data and the posterior, and compare that to the calibration plot.\n",
    "    color_map=[\"#377eb8\", \"#4daf4a\"]\n",
    "    fig = corner.corner(post_samples.reshape((-1,2)),bins=20,labels=['x','y'],show_titles=False, \n",
    "                        plot_datapoints=False,label_kwargs=dict(fontsize=15),levels=[0.68,0.95],dpi=1600, \n",
    "                        color=color_map[1],fill_contours=True,range=[[-6,6],[-6,6]])\n",
    "    fig.axes[2].plot(data[:,0],data[:,1],'.',c=color_map[0],alpha=0.1)\n",
    "    post_line = mlines.Line2D([], [], color=color_map[0], label='True Posterior')\n",
    "    data_line = mlines.Line2D([], [], color=color_map[1], label='Inferred Posterior')\n",
    "    plt.legend(handles=[data_line,post_line], bbox_to_anchor=(0.05, 1.0, 1., .0), loc=4,fontsize=12.0)\n",
    "    plt.show()\n",
    "    cal_fig = bnn_toy.plot_calibration(n_perc_points=30,title='',\n",
    "                                       legend=['Perfect Calibration','Inferred Posterior Calibration'])\n",
    "    return (fig,cal_fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate a single Gaussian from the multimodal data.\n",
    "data_means = [np.ones(2)*3,np.zeros(2)]\n",
    "data_covs = [np.array([[0.4,0],[0,0.4]]),np.array([[0.4,0],[0,0.4]])]\n",
    "ps = [0.9,0.1]\n",
    "toy_batch_size = 10000\n",
    "n_draws = 1000\n",
    "\n",
    "data = []\n",
    "for dmi in range(len(data_means)):\n",
    "    data.append(np.random.multivariate_normal(data_means[dmi],data_covs[dmi],(toy_batch_size//len(\n",
    "    data_mean))))\n",
    "data = np.concatenate(data,axis=0)\n",
    "\n",
    "post_mean = np.mean(data,axis=0)\n",
    "post_cov=np.diag(np.std(data,axis=0))\n",
    "post_fig, cal_fig = plot_toy_model_calibration_gm(data_means,data_covs,post_mean,post_cov,toy_batch_size,\n",
    "                                                  ps,n_draws,fit_guass_data=True)\n",
    "post_fig.savefig('../paper/figures/appendix/biv_corn.pdf')\n",
    "cal_fig.savefig('../paper/figures/appendix/biv_cal.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, the multimodal data leads to both under and over confidence by our network. In the interior region, corresponding to the principle mode, the toy prediction is has slightly too large covariances. In the tails, where our second mode becomes relevant, our single Gaussian prediction is suddenly very underconfident (since it assigns almost no weight to the second mode)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bnn",
   "language": "python",
   "name": "bnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
